{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. What are the three stages to build the hypotheses or model in machine learning?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three stages of building hyposthesis or model as as below:\n",
    "#### 1: Problem statement,data collection/preparation: \n",
    "--------------------------------------------------\n",
    "first of all we get problem statement like fruad incident, sales forcast, or trending in twitter. first step towards building a model is to collect the data for the given problem. In order to get the data, before that one has to determine whether it's superwise or unsuperwise problem. if superwise then desired output should be there is the dataset. In statistical terminology, datatset should contain independent and dependant variables both.else only independent variables are reuquired as in unsupervised learning we don't have predictor variable.After collecting the data, if its superwise learning problem we have to check one step ahead that whether its regression or classification problem. for calssification we have predictor variables as labeled data or categorical variable.\n",
    "\n",
    "for regression predicting variable will be a continuous numerical variable. \n",
    "\n",
    "#### 2.train the model\n",
    "----------------------\n",
    "to create a model first we provide training set which is major part of our dataset (let say 80 % of data) to algorithm. algorithm selection is based on nature of data and probelm we have undertaken. we train our model on training set and predict target variable. since we have train our model on training set, it gives good accuracy on training set but model can be biased or overfitted(predict correctly/classify correctly on given training set and performs poor on unseen data)\n",
    "\n",
    "#### 3.Test the model and deployment:\n",
    "------------------------------------------\n",
    "now to test our model we put test data on the model(test set is small part of the dataset which we don't use while training the model). and predict the dependant variable. using statistical metrics, one would check the performance of the model on unseen data and if it's good then model is put under production environment and works well on new/unseed data.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2. What is the standard approach to supervised learning?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The standard approach to supervised learning is to identify features and target variable. split the set of example into the training set and the test. after that apply algorithm depending upon the problem statement and end goals and test the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.What is Training set and Test set?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training set: \n",
    "\n",
    "Training set is dataset which is used to train the model. machine needs to be \"trained\" by explicitly feeding it data that has the correct answers attached. This training data will help the machine to connect the patterns in the data to the right answer. Once trained in this way, a machine can now be given test data that has no answers. The machine will then predict the answers based on the training it received. training data will have dependant or traget variable.\n",
    "\n",
    "\n",
    "Test set: \n",
    "\n",
    "Test set is part of dataset which is used to test the performance of the model.test data is used to see how well the machine can predict new answers based on its training. test set doesn't have dependant variable as far as superwise learning is considered. test set is relatively smaller than training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. What is the general principle of an ensemble method and what is bagging and boosting in ensemble method?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we try to predict the target variable using ML technique, the main cause of differnce in actual and predicted values are noise, variance and bias. Ensemble helps reducing these factors.  Ensemble is collection of predictors which come together (mean of all predictor) to give a final prediction. Many predictors trying to predict same target variable will perform a better job then single predictor.\n",
    "\n",
    "Bagging: Bagging is simple technique in which we build many independent model(weak learner) and combine them using aggregate function(majority vote, weighted average or normal average).\n",
    "\n",
    "Boosting: Boosting employes logic in which subsequent predictors learn from the mistakes of the previous predictors. Therefore, observation have unequal probability of appearing in subsequent models and one with highest error appear most."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. How can you avoid overfitting ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The possibility of over fitting exists as the criteria used for training the model is not the same as the criteria used to judge the efficacy of a model.\n",
    "\n",
    "By using a lot of data over fitting can be avoided, over fitting happens relatively as you have a small dataset, and you try to learn from it. But if you have a small database and you are forced to come with a model based on that. In such situation, you can use a technique known as cross validation.\n",
    "\n",
    "In this method the dataset splits into two section, testing and training datasets, the testing dataset will only test the model while, in training dataset, the data points will come up with the model.\n",
    "\n",
    "In this technique, a model is usually given a dataset of a known data on which training (training data set) is run and a dataset of unknown data against which the model is tested. The idea of cross validation is to define a dataset to “test” the model in the training phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
